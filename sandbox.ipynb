{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "from ngdlm import models as ngldmodels\n",
    "from ngdlm import utils as ngldutils\n",
    "from keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 32\n",
    "epochs = 50\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train- and test-data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_input_train, _), (x_input_test, _) = mnist.load_data()\n",
    "x_input_train = x_input_train.astype(\"float32\") / 255.0\n",
    "x_input_test = x_input_test.astype(\"float32\") / 255.0\n",
    "print(x_input_train.shape)\n",
    "print(x_input_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plain autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the encoder.\n",
    "encoder_input = layers.Input(shape=(28, 28))\n",
    "encoder_output = layers.Reshape((28 * 28,))(encoder_input)\n",
    "\n",
    "# Create the decoder.\n",
    "decoder_input = layers.Input(shape=(latent_dim,))\n",
    "decoder_output = layers.Dense(28 * 28, activation=\"sigmoid\")(decoder_input)\n",
    "decoder_output = layers.Reshape((28, 28))(decoder_output)\n",
    "\n",
    "# Create the autoencoder.\n",
    "ae = ngldmodels.AE(latent_dim=latent_dim)\n",
    "ae.set_encoder(encoder_input, encoder_output)\n",
    "ae.set_decoder(decoder_input, decoder_output)\n",
    "ae.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "# Train.\n",
    "print(\"Train...\")\n",
    "history = ae.fit(\n",
    "        x_input_train, x_input_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        validation_data=(x_input_test, x_input_test)\n",
    "    )\n",
    "    \n",
    "# Evaluate.\n",
    "print(\"Evaluate...\")\n",
    "loss = ae.model.evaluate(x_input_test, x_input_test)\n",
    "print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing plain autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render history.\n",
    "print(\"Rendering history...\")\n",
    "ngldutils.render_history(history)\n",
    "\n",
    "# Render conconstructions.\n",
    "print(\"Rendering reconstructions...\")\n",
    "ngldutils.render_image_reconstructions(ae, x_input_train, 10)\n",
    "\n",
    "# Render latent-space.\n",
    "print(\"Rendering latent-space...\")\n",
    "ngldutils.render_image_latent_space(ae.decoder, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
